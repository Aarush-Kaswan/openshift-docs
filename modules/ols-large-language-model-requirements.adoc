// This module is used in the following assemblies:

// * about/ols-about-openshift-lightspeed.adoc

:_mod-docs-content-type: CONCEPT
[id="ols-large-language-model-requirements"]
= Large Language Model (LLM) requirements 
:context: ols-large-language-model-requirements

As part of the {ols-release} release, {ols-long} can rely on the following Software as a Service (SaaS) Large Language Model (LLM) providers: 

* OpenAI

* {azure-openai}

* {watsonx}

[NOTE]
====
Many self-hosted or self-managed model servers claim API compatibility with OpenAI. It is possible to configure the OpenShift Lightspeed OpenAI provider to point to an API-compatible model server. If the model server is truly API-compatible, especially with respect to authentication, then it may work. These configurations have not been tested by Red Hat, and issues related to their use are outside the scope of {ols-release} support.
====

For {ols-long} configurations with {rhoai}, you must host your own LLM provider.
