:_mod-docs-content-type: CONCEPT
[id="ols-large-language-model-requirements"]
= Large Language Model (LLM) Requirements 
:context: ols-large-language-model-requirements

As part of the {ols-release}  release, {ols-long} relies on Software as a Service (SaaS) LLM providers. You will need to have either a trial or paid subscription that allows for API access to completions and inferences with one of the following providers:

* OpenAI

* Azure OpenAI

* WatsonX

[NOTE]
====
Many self-hosted or self-managed model servers claim API compatibility with OpenAI. It is possible to configure the OpenShift Lightspeed OpenAI provider to point to an API-compatible model server. If the model server is truly API-compatible, especially with respect to authentication, then it may work. These configurations have not been tested by Red Hat, and issues related to their use are outside the scope of {ols-release} support.
====

