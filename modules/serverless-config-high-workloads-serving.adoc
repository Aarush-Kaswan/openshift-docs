// Module included in the following assemblies:
//
// * /knative-serving/scalability-and-performance-serving.adoc


:_mod-docs-content-type: PROCEDURE
[id="serverless-config-high-workloads-serving_{context}"]
= Configuring Serving for high workloads

You can configure Knative Serving for high workloads using the `KnativeServing` custom resource (CR).
The following findings are relevant to configuring Knative Serving for a high workload:

[NOTE]
====
These findings have been tested with requests with a payload size of 0-32 kb. The Knative Service backends used in those tests had a startup latency between 0 to 10 seconds and response times between 0 to 5 seconds.
====

* All data-plane components are mostly increasing CPU usage on higher requests and payload scenarios, so the CPU requests and limits have to be tested and potentially increased.
* The activator component also might need more memory, when it has to buffer more or bigger request payloads, so the memory requests and limits might need to be increased as well.
* One activator pod can handle approximately 2500 requests per second before it starts to increase latency and, at some point, leads to errors.
* One `3scale-kourier-gateway` or `istio-ingressgateway` pod can also handle approximately 2500 requests per second before it starts to increase latency and, at some point, leads to errors.
* Each of the data-plane components consumes up to 1 vCPU of CPU for handling 2500 requests per second. Note that this highly depends on the payload size and the response times of the Knative Service backend.

[IMPORTANT]
====
Fast startup and fast response-times of your Knative Service user workloads are critical for good performance of the overall system. The Knative Serving components are buffering incoming requests when the Knative Service user backend is scaling up or when request concurrency has reached its capacity. If your Knative Service user workload introduces long startup or request latency, it will either overload the `activator` component (when the CPU and memory configuration is too low) or lead to errors for the calling clients.
====

.Procedure

* To fine-tune your installation, use the previous findings combined with your own test results to configure the `KnativeServing` custom resource:
+
.A high workload configuration in KnativeServing CR
[source,yaml]
----
apiVersion: operator.knative.dev/v1beta1
kind: KnativeServing
metadata:
  name: knative-serving
  namespace: knative-serving
spec:
  high-availability:
    replicas: 2 <1>
  workloads:
    - name: component-name <2>
      replicas: 2 <3>
      resources:
        - container: container-name
          requests:
            cpu: <4>
            memory:
          limits:
            cpu:
            memory:
  podDisruptionBudgets: <5>
    - name: name-of-pod-disruption-budget
      minAvailable: 1
----
<1> Set this parameter to at least `2` to make sure you always have at least two instances of every component running. You can also use `workloads` to override the replicas for certain components.
<2> Use the `workloads` list to configure specific components. Use the `deployment` name of the component and set the `replicas` field. 
<3> For the `activator`, `webhook`, and `3scale-kourier-gateway` components, which use horizontal pod autoscalers (HPAs), the `replicas` field sets the minimum number of replicas. The actual number of replicas depends on the CPU load and scaling done by the HPAs.
<4> Set the requested and limited CPU and memory according to at least the idle consumption while also taking the previous findings and your own test results into consideration.
<5> Adjust the `PodDistruptionBudgets` to a value lower than `replicas` to avoid problems during node maintenance. The default `minAvailable` is set to `1`, so if you increase the required replicas, you must also increase `minAvailable`.

[IMPORTANT]
====
As each environment is highly specific, it is essential to test and find your own ideal configuration.
Use the monitoring and alerting functionality of {ocp-product-title} to continuously monitor your actual resource consumption and make adjustments if needed.

If you are using the {ServerlessProductName} and {SMProductShortName} integration, additional CPU processing is added by the `istio-proxy` sidecar containers.
For more information about this, see the {SMProductShortName} documentation.
====
