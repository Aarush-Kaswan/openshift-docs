// This module is used in the following assemblies:
// configure/ols-configuring-openshift-lightspeed.adoc

:_mod-docs-content-type: PROCEDURE
[id="ols-creating-lightspeed-custom-resource-file-using-web-console_{context}"]
= Creating the Lightspeed custom resource file using the web console

The Custom Resource (CR) file contains information that the Operator uses to deploy {ols-long}. The specific content of the CR file is unique for each LLM provider. Choose the configuration file that matches your LLM provider.

.Prerequisites

* You are logged in to the {ocp-product-title} web console as a user with the `cluster-admin` role. Alternatively, you are logged in to a user account that has permission to create a cluster-scoped custom resource file.

* You have installed the {ols-long} Operator.

.Procedure 

. Click the plus button in the upper-right corner of the {ocp-short-name} web console.

. Paste the YAML content for the LLM provider you use into the text area of the web console:
+
.OpenAI custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myOpenai
        type: openai
        credentialsSecretRef:
          name: credentials
        url: "https://api.openai.com/v1"
        models:
          - name: gpt-3.5-turbo
  ols:
    defaultModel: gpt-3.5-turbo
    defaultProvider: myOpenai
----
+
.{azure-openai} custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - credentialsSecretRef:
          name: credentials
        deploymentName: <azure_ai_deployment_name>
        models:
          - name: gpt-35-turbo-16k
        name: myAzure
        type: azure_openai
        url: <azure_ai_deployment_url>
  ols:
    defaultModel: gpt-35-turbo-16k
    defaultProvider: myAzure
----
+
.{watsonx} custom resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myWatsonx
        type: watsonx
        credentialsSecretRef:
          name: credentials
        url: <ibm_watsonx_deployment_name>
        projectId: <ibm_watsonx_project_id>
        models:
          - name: ibm/granite-13b-chat-v2
  ols:
    defaultModel: ibm/granite-13b-chat-v2
    defaultProvider: myWatsonx
----

. Click *Create*.