// This module is used in the following assemblies:
// configure/ols-configuring-openshift-lightspeed.adoc

:_mod-docs-content-type: PROCEDURE
[id="ols-creating-lightspeed-custom-resource-file-using-web-console_{context}"]
= Creating the Lightspeed custom resource file using the web console

The specific content of the custom resource file that the Operator uses to deploy {ols-long} is unique for each LLM provider. Choose the configuration that matches your LLM provider.

.Prerequisites

* You are logged in to the {ocp-product-title} web console as a user with the `cluster-admin` role.

* You have access to the {ocp-short-name} CLI (oc).

* You have installed the {ols-long} Operator.

.Pocedure 

. Click the plus button in the upper-right corner of the {ocp-short-name} web console.

. Paste the YAML content for the LLM provider you use into the text area of the web console:
+
.Example OpenAI customer resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myOpenai
        type: openai
        credentialsSecretRef:
          name: credentials
        url: "https://api.openai.com/v1"
        models:
          - name: gpt-3.5-turbo
  ols:
    defaultModel: gpt-3.5-turbo
    defaultProvider: myOpenai
    logLevel: DEBUG
----
+
.Example Azure OpenAI customer resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - credentialsSecretRef:
          name: credentials
        deploymentName: <USE THE NAME OF THE DEPLOYMENT YOU CREATED EARLIER>
        models:
          - name: gpt-35-turbo-16k
        name: myAzure
        type: azure_openai
        url: <USE THE URL YOU RECORDED EARLIER>
  ols:
    defaultModel: gpt-35-turbo-16k
    defaultProvider: myAzure
    logLevel: DEBUG
----
+
.Example WatsonX customer resource file
+
[source,yaml, subs="attributes,verbatim"]
----
apiVersion: ols.openshift.io/v1alpha1
kind: OLSConfig
metadata:
  name: cluster
spec:
  llm:
    providers:
      - name: myWatsonx
        type: watsonx
        credentialsSecretRef:
          name: credentials
        url: <APPROPRIATE URL FROM REGIONAL URLS>
        projectId: <your project ID>
        models:
          - name: ibm/granite-13b-chat-v2
  ols:
    defaultModel: ibm/granite-13b-chat-v2
    defaultProvider: myWatsonx
    logLevel: DEBUG
----

. Click *Create*.